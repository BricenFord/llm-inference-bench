#!/usr/bin/env python3

import requests
import time

HOST = "{{HOST}}"
MODEL_NAME = "{{MODEL_NAME}}"
CSV_FILE = "{{CSV_FILE}}"
TIMEOUT_S = {{TIMEOUT_S}}

def load_questions(file_path: str):
    questions = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                questions.append(line)
    return questions

def ask_model(prompt: str):
    payload = {"model": MODEL_NAME, "prompt": prompt, "stream": False}
    start_time = time.time()
    try:
        resp = requests.post(f"{HOST}/api/generate", json=payload, timeout=TIMEOUT_S)
        resp.raise_for_status()
    except requests.exceptions.Timeout:
        raise RuntimeError(f"Request timed out for prompt: {prompt}")
    except requests.exceptions.RequestException as e:
        raise RuntimeError(f"HTTP error for prompt: {prompt} | {e}")
    latency = time.time() - start_time
    answer = resp.json().get("response", "").strip()
    return answer, latency

def main():
    questions = load_questions(CSV_FILE)
    total_questions = len(questions)
    start_total = time.time()

    for i, question in enumerate(questions, start=1):
        try:
            answer, latency = ask_model(question)
        except Exception as e:
            print(f"{i}, ERROR, {e}", flush=True)
            continue

        elapsed_total = time.time() - start_total
        throughput = i / elapsed_total if elapsed_total > 0 else 0
        print(f"{i}, {latency:.3f}s, {throughput:.3f} q/s, {answer}", flush=True)

    total_time = time.time() - start_total
    overall_throughput = total_questions / total_time if total_time > 0 else 0

    print(f"\nTotal questions: {total_questions}")
    print(f"Total time: {total_time:.2f} seconds")
    print(f"Overall throughput: {overall_throughput:.2f} questions/sec")

if __name__ == "__main__":
    main()